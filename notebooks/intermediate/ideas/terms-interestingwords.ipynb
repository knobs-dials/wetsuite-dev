{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose of this notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"So how you detect interesting phrases?\"\n",
        "\n",
        "Annoyingly, one has to respond with \"that depends on what you mean with interesting phrases\"\n",
        "\n",
        "\n",
        "There are varied methods, some simple enough that you could implement yourself in half an hour,\n",
        "that will return with some interesting fragments, so seem to work. \n",
        "...yet often have assumptions that turn out to not match up with what you thought when you heard 'interesting'.\n",
        "\n",
        "For example, tf-idf (on n-grams) can tell you which combinations of words are more common than others,\n",
        "but little about how they compare, so it's messy to work with.\n",
        "\n",
        "Collocation analysis often refers to a probability-based method, based on \"does this combination of words appears more often together\n",
        "than the basic probability of the components would suggest\", which works a little better. \n",
        "Say, it will pick up phrases that have legal meaning (\"eigen gebruik\", \"echtgenoot of geregistreerde partner\", \"werk en inkomen naar arbeidsvermogen\"),\n",
        "but also just fragments that happen, well, because sentences have structure (\"heeft gedaan\", \"verplichtingen uit\"),\n",
        "including some that seem arbitrarily ripped from their context (\"tijdstip zal\", \"KONING DER\").\n",
        "'More common together' turns out to not be quite enough for clean output.\n",
        "\n",
        "\n",
        "Point is, these methods visible do useful things, but it may be invisible what it misses, and why.\n",
        "\n",
        "So when your actual goal was \n",
        "\"what multi-word phrases appear in this document\" \n",
        "\"what multi-word phrases make this document interesting\" \n",
        "\"what multi-word phrases make this document different from others in a set\" \n",
        "\"can we make lists of words\" \n",
        "\"what multi-word phrases make this document interesting\" \n",
        "may seem like subtle variations, but in terms of wanting clear and full answers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* match known phrases\n",
        "  aside from legal terms, there are a lot of very regular phrases that will be used more or less verbatim\n",
        "\n",
        "* match specific patterns \n",
        "  \n",
        "\n",
        "* find reguilar combinations\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3NCj8rkQMsdx"
      },
      "source": [
        "## Intro to spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-20 19:15:35.725098: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import spacy.displacy\n",
        "\n",
        "import wetsuite.helpers.spacy    # some helpers of our own, barely used here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EUJ1XGlDMseC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/util.py:877: UserWarning: [W095] Model 'nl_core_news_lg' (3.4.0) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.5.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "dutch  = spacy.load('nl_core_news_lg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vfiotnDMseW",
        "outputId": "89de2461-a9e1-4495-a1ce-be39f895473b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOKENS\n",
            "  Machine/NOUN  learning/NOUN  can/AUX  be/AUX  easy/ADJ  ./PUNCT  Deep/PROPN  Learning/PROPN  is/AUX  n't/PART  straightforward/ADJ  ./PUNCT  Ducks/NOUN  are/AUX  nice/ADJ  ./PUNCT  Cats/NOUN  and/CCONJ  dogs/NOUN  are/AUX  cute/ADJ  ./PUNCT  Neural/ADJ  nets/NOUN  are/AUX  useful/ADJ  ./PUNCT  Long/PROPN  Cat/PROPN  looks/VERB  like/ADP  a/DET  name/NOUN  ./PUNCT\n",
            "\n",
            "SENTENCES\n",
            "  Machine learning can be easy.\n",
            "  Deep Learning isn't straightforward.\n",
            "  Ducks are nice.\n",
            "  Cats and dogs are cute.\n",
            "  Neural nets are useful.\n",
            "  Long Cat looks like a name.\n"
          ]
        }
      ],
      "source": [
        "#wetsuite.helpers.spacy.sentence_split()\n",
        "\n",
        "statements_doc = dutch( statements_txt )\n",
        "\n",
        "print(\"TOKENS\")\n",
        "for tok in statements_doc: \n",
        "    print( '  %s/%s'%(tok.text,  tok.pos_),  end='' )  # print token text, and its part of speech tag\n",
        "\n",
        "\n",
        "print(\"\\n\\nSENTENCES\")\n",
        "for sent in statements_doc.sents:  # https://spacy.io/api/doc#sents\n",
        "    print( '  %s'%sent.text )\n",
        "    #for tok in sent: \n",
        "    #    print( '  %s/%s'%(tok.text,  tok.pos_), end='' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to org\n",
        "Absolute competentie\n",
        "Aanhangig maken\n",
        "\n",
        "Aanhouden\n",
        "Aanleg\n",
        "Aanwijzing\n",
        "Aanzegging\n",
        "Administratieve afhandeling\n",
        "Akte\n",
        "Appèl\n",
        "Arrest\n",
        "Bewaring\n",
        "Benadeelde partij\n",
        "Beroep\n",
        "Beroepschrift\n",
        "Beklag\n",
        "Bemiddeling\n",
        "Beschikking\n",
        "Arrondissement\n",
        "Arrondissementsparket\n",
        "\n",
        "Beëindigingovereenkomst\n",
        "\n",
        "Bestuursorganen\n",
        "\n",
        "Advocaat\n",
        "Advocaat-generaal\n",
        "Appellant\n",
        "Alternatieve sanctie\n",
        "Ambtshalve toevoeging\n",
        "\n",
        "Bevoegdheid\n",
        "\n",
        "Balie\n",
        "Belanghebbende\n",
        "Belofte\n",
        "Beslag\n",
        "Bestuursrechtspraak\n",
        "Betekening\n",
        "Bewijs\n",
        "Bewijslast\n",
        "Bewijsmiddelen\n",
        "Bezwaar\n",
        "Bodemprocedure\n",
        "Buitengerechtelijke kosten\n",
        "Cassatie\n",
        "Casseren\n",
        "Cautie\n",
        "College van procureurs-generaal\n",
        "Comparitie\n",
        "Comparitie van partijen\n",
        "Compenseren\n",
        "Competentie\n",
        "Conclusie van antwoord\n",
        "Contra-expertise\n",
        "Contradictoir\n",
        "Cumulatie\n",
        "Cumulatieve tenlastelegging\n",
        "Curator\n",
        "Dader\n",
        "Dading\n",
        "Dagvaarding\n",
        "Dagvaardingsprocedure\n",
        "Descente\n",
        "Delict\n",
        "Derdenverzet\n",
        "Deurwaarder\n",
        "Deurwaardersexploot\n",
        "Discretionaire bevoegdheid\n",
        "Doodslag\n",
        "Dupliek\n",
        "Dwangmiddelen\n",
        "Dwangsom\n",
        "Eed of belofte\n",
        "Eenvoudig/enkelvoudig delict\n",
        "Eerste/primaire vordering\n",
        "Eerste en enige aanleg\n",
        "Eerste instantie (eerste aanleg)\n",
        "Eis\n",
        "Eiser\n",
        "Elektronisch toezicht \n",
        "Enkelvoudige kamer\n",
        "Enquête\n",
        "Ex nunc\n",
        "Ex tunc\n",
        "Executie van een vonnis \n",
        "Executoriaal beslag\n",
        "Executoriale titel\n",
        "Exploot (of Exploit)\n",
        "Formeel recht\n",
        "Fourneren\n",
        "Gedaagde\n",
        "Gedetineerde\n",
        "Gelaedeerde\n",
        "Geïntimeerde\n",
        "Geldelijk belang\n",
        "Gemachtigde\n",
        "Geopposeerde\n",
        "Gerecht\n",
        "Gerechtsauditeur\n",
        "Gerechtsdeurwaarder\n",
        "Gerechtssecretaris\n",
        "Gerechtshof\n",
        "Gerekestreerde\n",
        "Getuige à charge\n",
        "Getuige à decharge\n",
        "Gevangenhouding\n",
        "Griffie\n",
        "Grondwet\n",
        "Grosse\n",
        "Hechtenis\n",
        "Heenzenden\n",
        "Herziening\n",
        "Hof (zie gerechtshof)\n",
        "Hoger beroep\n",
        "Hoorzitting\n",
        "Huis van bewaring\n",
        "Huisarrest (zie elektronisch toezicht)\n",
        "Huiszoeking\n",
        "Hulpofficier van justitie \n",
        "Inbewaringstelling \n",
        "Incidenteel appèl\n",
        "Incidenteel tussengeschil\n",
        "Inlichtingencomparitie\n",
        "Immateriële schade\n",
        "Inverzekeringstelling\n",
        "Jeugdstrafrecht\n",
        "Jurisprudentie\n",
        "Jurist\n",
        "(Vrouwe) Justitia\n",
        "Justitie\n",
        "Justitiële Documentatiedienst\n",
        "Justitiële rechtzoekende\n",
        "Kamer\n",
        "Kantonrechtersformule\n",
        "Kinderstrafrecht\n",
        "Klachtdelict\n",
        "Kort geding\n",
        "Kracht van gewijsde\n",
        "Kwalificatie in het strafrecht\n",
        "Landsadvocaat\n",
        "Leerstraf\n",
        "Legalisatie\n",
        "Litispendentie \n",
        "Lijdelijk\n",
        "Lik op stuk\n",
        "Maatregel\n",
        "Magistratuur\n",
        "Materiële schade\n",
        "Meervoudige kamer\n",
        "Meineed\n",
        "Memorie van antwoord\n",
        "Memorie van grieven\n",
        "Minuut\n",
        "Misdrijf\n",
        "Mondelinge uitspraak\n",
        "Moord\n",
        "Mulder-afdoening\n",
        "Ne bis in idem\n",
        "Niet-ontvankelijk\n",
        "Nietigverklaring\n",
        "Non-refoulement\n",
        "Noodweer\n",
        "Noodweerexces\n",
        "Novum\n",
        "Officier van justitie\n",
        "OM\n",
        "Ondercuratelestelling\n",
        "Onderbewindstelling\n",
        "Onherroepelijk\n",
        "Onrechtmatig bewijs\n",
        "Ontoerekeningsvatbaar\n",
        "Ontslag van rechtsvervolging\n",
        "Onvoorwaardelijke straf\n",
        "Openbaar Ministerie\n",
        "Openbare registers\n",
        "Opportuniteitsbeginsel\n",
        "Opposant\n",
        "Oproeping\n",
        "Oproepingsbericht\n",
        "Overtreding\n",
        "Parket\n",
        "Parketnummer\n",
        "Passant\n",
        "Penitentiaire inrichting\n",
        "Peremptoire termijn\n",
        "Persisteren\n",
        "Piketdienst\n",
        "Plaatsopneming\n",
        "Pleidooi\n",
        "Pluk-ze\n",
        "Politierechter\n",
        "Preparatoir vonnis\n",
        "President\n",
        "Preventieve hechtenis\n",
        "Principaal beroep\n",
        "Privaatrecht\n",
        "Pro-deoadvocaat\n",
        "Proceshandelingen\n",
        "Procesinleiding\n",
        "Proceskosten\n",
        "Proceskostenveroordeling\n",
        "Procureur-generaal (pg)\n",
        "Proeftijd\n",
        "Proces-verbaal\n",
        "Pro-formazitting\n",
        "Prorogatie\n",
        "Raadkamer\n",
        "Raadsheer\n",
        "Raadsman\n",
        "Raadsvrouw\n",
        "Raio\n",
        "Rechtbank\n",
        "Rechter-commissaris\n",
        "Rechterlijke macht\n",
        "Reconventie\n",
        "Redelijkheidsbeginsel\n",
        "Referte\n",
        "Regiezitting\n",
        "Rekest\n",
        "Relatieve competentie\n",
        "Repliek\n",
        "Requestrant (of rekwestrant)\n",
        "Requirant\n",
        "Requireren\n",
        "Requisitoir\n",
        "Ressort\n",
        "Ressortsparket\n",
        "Rogatoire commissie\n",
        "Rol\n",
        "Rolzaak\n",
        "Rolzitting\n",
        "Royement/royeren\n",
        "Sanctie\n",
        "Saniet\n",
        "Schikking\n",
        "Schouw\n",
        "Seponeren\n",
        "Sprongcassatie\n",
        "Staande magistratuur (zie magistratuur)\n",
        "Strafblad\n",
        "Strafbeschikking\n",
        "Strafkamer\n",
        "Strafrechtspraak\n",
        "Strafregister\n",
        "Subsidiair\n",
        "Tenlastelegging\n",
        "Tenuitvoerlegging\n",
        "Toevoeging\n",
        "Transactie\n",
        "Tussenkomst\n",
        "Tussenuitspraak\n",
        "Uitspraak\n",
        "Uitvoerbaar bij voorraad\n",
        "Unus-rechtspraak\n",
        "Verbeurdverklaren\n",
        "Verdagen\n",
        "Verhaal\n",
        "Verjaring\n",
        "Verlofstelsel\n",
        "Verplichte procesvertegenwoordiging \n",
        "Verschoningsrecht\n",
        "Verstek\n",
        "Verstekvonnis of bij verstek veroordeeld zijn\n",
        "Vertrouwensbeginsel\n",
        "Vervangende hechtenis\n",
        "Verweerder\n",
        "Verzet\n",
        "Verzoeker\n",
        "Verzoekschrift\n",
        "Verzoekschriftprocedure\n",
        "Verzuim\n",
        "Voeging\n",
        "Vonnis\n",
        "Voorgeleiding\n",
        "Voorlopig getuigenverhoor\n",
        "Voorlopige hechtenis\n",
        "Voorlopige voorziening\n",
        "Voorwaardelijke straf\n",
        "Vorderingsprocedure\n",
        "Vormverzuim\n",
        "Vrijspraak\n",
        "Vrijwaring\n",
        "(Vrouwe) Justitia\n",
        "Wederrechtelijk\n",
        "Zekerheidsstelling\n",
        "Zittende magistratuur (zie magistratuur)\n",
        "Zitting\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Af84RatRW2p8"
      },
      "source": [
        "# Slightly less basic"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xWwcIzGnMsel"
      },
      "source": [
        "## Extracting patterns with rule-based matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUZtIYIPMsem",
        "outputId": "8f9bb340-5510-4fa0-b434-7f8b0d88e5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Revolution names\n",
            "-Revolution names\n",
            "pre-Revolution names\n",
            "constitutional monarch\n",
            "first railway\n",
            "new period\n",
            "massive migration\n",
            "popular uprising\n",
            "public works\n",
            "gigantic public works\n",
            "new boulevards\n",
            "wide new boulevards\n",
            "new opera\n",
            "central market\n",
            "new aqueducts\n"
          ]
        }
      ],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Look for   one or more adjectives  before  a noun or proper noun\n",
        "an_pattern = [\n",
        "    [ {\"POS\": \"ADJ\", \"OP\": \"+\"},   {\"POS\": {\"IN\":[\"NOUN\",\"PROPN\"]}} ],\n",
        "    # you can have more rules in a matcher\n",
        "]\n",
        "matcher = Matcher(english_trf.vocab)\n",
        "matcher.add(\"adjective-noun\", an_pattern)\n",
        "matches = matcher( paris_doc )\n",
        "for match_id, start_i, end_i in matches:\n",
        "    print( paris_doc[ start_i : end_i ] ) # from the indices, print the described span \n",
        "\n",
        "# Notes: \n",
        "# - you can express more complex types of patterns, see https://spacy.io/api/matcher#patterns\n",
        "# - You could extend this to more complex tasks, like maybe rule-based phrase and named entity extraction.\n",
        "#   - ...though you might base that on more specific existing code like PhraseMatcher and EntityRuler,\n",
        "#     which may work faster and/or annotate automatically.\n",
        "#   - and in the case of NER would probaly still be less effective than existing trained NER model components\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aDinb2pLMseq"
      },
      "source": [
        "##  Inventing your own functions to apply to spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTrSQV8Mses",
        "outputId": "e722fefc-694d-4c86-e50a-f0b9850aa568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[During the Restoration, the bridges and squares of Paris were returned to their pre-Revolution names; the July Revolution in 1830  (commemorated by the July Column on the Place de la Bastille) brought a constitutional monarch, Louis Philippe I, to power.]\n",
            "Complexity: 4.3\n",
            "\n",
            "[The first railway line to Paris opened in 1837, beginning a new period of massive migration from the provinces to the city.]\n",
            "Complexity: 2.4\n",
            "\n",
            "[Louis-Philippe was overthrown by a popular uprising in the streets of Paris in 1848.]\n",
            "Complexity: 2.5\n",
            "\n",
            "[His successor, Napoleon III,  alongside the newly appointed prefect of the Seine, Georges-Eugène Haussmann, launched a gigantic public works project to  build wide new boulevards, a new opera house, a central market, new aqueducts, sewers and parks, including the Bois de Boulogne  and Bois de Vincennes.]\n",
            "Complexity: 4.4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def complexity( span ):\n",
        "    ''' Takes a parsed spacy sentence, and estimates its complexity.\n",
        "\n",
        "        Currently uses _only_ the average distance of the dependencies, which is decent for how basic it is. \n",
        "        Consider e.g.\n",
        "        - long sentences are often more complex, but not proportional to their length\n",
        "          They might, say, separate independent clauses.\n",
        "          They become harder to parse e.g. if there are references to something further away.\n",
        "        - parenthetical sentences will lengthen references across them\n",
        "        - lists and flat compounds will drag the complexity down\n",
        "        which all seem to make basic sense.\n",
        "\n",
        "        We don't even really need normalization, in that the units is 'token distance' (though we should take more care across PUNCT and such)\n",
        "\n",
        "        Downsides include that spacy seems to assign some dependencies just because it needs to, not necessarily because they are linguistically sensible.\n",
        "        Also, we should probably count most named entities as a single thing, not the amount of tokens in them\n",
        "    '''\n",
        "    # this idea happens to be easy to implement, because every token has a relation .head, and every token has a position\n",
        "    dists = []\n",
        "    for tok in span:\n",
        "        dist = tok.head.i - tok.i\n",
        "        dists.append( dist ) \n",
        "    abs_dists = list( abs(d)  for d in dists )\n",
        "    avg_dist = float(sum(abs_dists)) / len(abs_dists)\n",
        "    return avg_dist\n",
        "\n",
        "\n",
        "for sent in english_trf( paris_doc ).sents:\n",
        "    print('[%s]\\nComplexity: %.1f\\n'%(sent.text.replace('\\n',' ').strip(), complexity(sent) ) )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r32o_hmgMses"
      },
      "source": [
        "## Some specialized models\n",
        "\n",
        "Take a look around existing models.\n",
        "There are sometimes readymade models that help do specific tasks, and then possibly _only_ those tasks.\n",
        "\n",
        "Say you have a text that you know contains multiple languages, and you want to feed each to a parser for that language:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qt3KKiCMset"
      },
      "source": [
        "### Language detection\n",
        "useful to take multiple languages in one piece of text, and be able to feed it to the right nlp object.\n",
        "\n",
        "There is a [spacy_fastlang](https://pypi.org/project/spacy-fastlang/) library (which depends on the [fasttext](https://fasttext.cc/) library) that can do that for you.\n",
        "\n",
        "The below uses our own helper function called `detect_language()`, which is a handful of lines mostly jut doing the boilerplate of \"create model, stick fastlang on it, run it, and report the best-scoring language and (our certainty it's correct)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjJflUfiMset"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet spacy_fastlang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5_mzJFjMseu",
        "outputId": "f72454be-fd44-4a2a-92ac-f41949c19236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANGUAGE DETECTION\n",
            "    en (certainty: 0.73) for  'I am cheese'\n",
            "    nl (certainty: 0.53) for  'Ik ben kaas'\n",
            "    fr (certainty: 1.00) for  'Je suis fromage'\n",
            "    de (certainty: 1.00) for  'Ich bin Käse'\n",
            "    af (certainty: 0.66) for  'Ek is kaas'\n",
            "    id (certainty: 0.58) for  'Saya keju'\n",
            "    fi (certainty: 0.91) for  'Olen juusto'\n",
            "    tr (certainty: 0.29) for  'ben peynirim'\n"
          ]
        }
      ],
      "source": [
        "print(\"LANGUAGE DETECTION\")\n",
        "for example in (\"I am cheese\", \"Ik ben kaas\", \"Je suis fromage\", \"Ich bin Käse\", \"Ek is kaas\", \"Saya keju\", \"Olen juusto\", \"ben peynirim\"):\n",
        "    lang, score = wetsuite.helpers.spacy.detect_language(example)\n",
        "    print( \"    %s (certainty: %.2f) for  %r\"%( lang, score, example ) )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "14hkvLJdMsev"
      },
      "source": [
        "### Sentence splitting\n",
        "\n",
        "Some models use rule based sentence splitting that happens to be... not great, or somewhat unpredictable.\n",
        "For one example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Wario Land <span style=\"color:red\">//</span> 4 ( Japans : ワリオランドアドバンス; <span style=\"color:red\">//</span> Wario Land Advance ) is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001. <span style=\"color:red\">//</span> Wario Land <span style=\"color:red\">//</span> 4 ( Japans : ワリオランドアドバンス; <span style=\"color:red\">//</span> Wario Land Advance ) is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Wario Land <span style=\"color:red\">//</span> 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001. <span style=\"color:red\">//</span> Wario Land <span style=\"color:red\">//</span> 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Land 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001. <span style=\"color:red\">//</span> Land 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dutch = spacy.load('nl_core_news_lg')\n",
        "\n",
        "from IPython.display import HTML  # this uses HTML output to mark the split unambiguously. A little overkill, but clear.\n",
        "splitter = ' <span style=\"color:red\">//</span> '\n",
        "\n",
        "for txt in (\n",
        "        'Wario Land 4 ( Japans : ワリオランドアドバンス; Wario Land Advance ) is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001.',\n",
        "        'Wario Land 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001.',\n",
        "        #'Wario 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001.',\n",
        "        'Land 4 is een platformspel, uitgebracht voor de Game Boy Advance in Europa op 16 november 2001.',\n",
        "    ):\n",
        "    display( HTML( splitter.join( s.text for s in dutch(txt+' '+txt).sents) ) )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have no idea why it does that and why it seems to vary so much.  I just know we can get better.\n",
        "\n",
        "For example, the [xx_sent_ud_sm](https://spacy.io/models/xx#xx_sent_ud_sm) model is trained on multiple languages. \n",
        "Even if it's not better, it is more of a known quantity than 'whatever the model you use today happens to do'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XuQCOHeMsew"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download xx_sent_ud_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxLMnQ7yMsey",
        "outputId": "06b9bfc3-8e79-4ac8-80df-a3cfc550f024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SENTENCE SPLITTING\n",
            "    [fr] C'est n'est pas une pipe.\n",
            "    [en] A capital after Mr. Abbreviation might throw things off.\n",
            "    [en] (Also) weird sentence starts could.\n",
            "    [en] As can ellipses... as you can imagine.\n",
            "    [en] As could \"Things we quote?\"\n",
            "    [en] ...as they are embedded sentences and what comes after is unknown.\n",
            "    [nl] (en die laatste zou anders werken met een komma)\n"
          ]
        }
      ],
      "source": [
        "print(\"SENTENCE SPLITTING\")\n",
        "split_doc = wetsuite.helpers.spacy.sentence_split(\"\"\"C'est n'est pas une pipe. A capital after Mr. Abbreviation might throw things off. (Also) weird sentence starts could. \n",
        "     As can ellipses... as you can imagine. As could \"Things we quote?\" ...as they are embedded sentences and what comes after is unknown. (en die laatste zou anders werken met een komma)\"\"\") \n",
        "\n",
        "for sent in split_doc.sents:\n",
        "    text = sent.text.strip()\n",
        "    print('    [%s] %s'%( wetsuite.helpers.spacy.detect_language(text)[0], text ) )   # add language detection, as per our initial plan"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
