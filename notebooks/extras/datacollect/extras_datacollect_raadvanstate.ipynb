{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, datetime, time, json, random, pprint, urllib.parse\n",
    "\n",
    "import bs4\n",
    "\n",
    "import wetsuite.helpers.localdata\n",
    "import wetsuite.helpers.etree\n",
    "import wetsuite.helpers.net\n",
    "import wetsuite.helpers.format\n",
    "import wetsuite.helpers.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractParagraphs:\n",
    "    ''' Helps fetch the \"Volledige tekst\" part of a etree'd HTML page, with minor interpretation of its HTML \n",
    "        (that node logic is somewhat explicit to be able to refine that - and to have it explicit what we're not handling yet)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.pars   = []\n",
    "        self.curpar = []\n",
    "        self.links  = []\n",
    "\n",
    "    def flush_curpar(self):\n",
    "        if len(self.curpar)>0:\n",
    "            self.pars.append( ' '.join(self.curpar) )\n",
    "            self.curpar = []\n",
    "\n",
    "    def _handle(self, elem, page_url):\n",
    "        ' Generally expects to be handed a <p> '\n",
    "        for thing in elem.contents:\n",
    "            if type(thing) is bs4.NavigableString:\n",
    "                self.curpar.append( str(thing) ) # TODO: is that the best way to get the text?\n",
    "\n",
    "            elif thing.name == 'em':\n",
    "                self.curpar.append( thing.text )\n",
    "\n",
    "            elif thing.name == 'span':     # TODO: check what these actually are\n",
    "                self.flush_curpar()\n",
    "                #print( thing )\n",
    "                self.curpar.append( thing.text )\n",
    "                self.flush_curpar()\n",
    "\n",
    "            elif thing.name == 'sub':      # TODO: current code will separate that, which it probably shouldn't be.\n",
    "                self.curpar.append( thing.text )\n",
    "            elif thing.name == 'sup':\n",
    "                self.curpar.append( thing.text )\n",
    "\n",
    "            elif thing.name == 'br':\n",
    "                self.flush_curpar()\n",
    "\n",
    "            elif thing.name == 'hr':\n",
    "                self.flush_curpar()\n",
    "\n",
    "            elif thing.name == 'strong':\n",
    "                # TODO: see if it's a header. Currently sort of assumed to be at least a paragraph splitter\n",
    "                # note: headers generally are a <strong> - but they may not be part of the <p> you think.\n",
    "                self.flush_curpar()\n",
    "                self.curpar.append( \n",
    "                        #'[%s]'%\n",
    "                        thing.text\n",
    "                )\n",
    "                self.flush_curpar()\n",
    "\n",
    "            elif thing.name == 'h2':\n",
    "                self.flush_curpar()\n",
    "                self.curpar.append( thing.text )\n",
    "                self.flush_curpar()\n",
    "\n",
    "            elif thing.name == 'h3':\n",
    "                self.flush_curpar()\n",
    "                self.curpar.append( thing.text )\n",
    "                self.flush_curpar()\n",
    "\n",
    "            elif thing.name == 'h4':\n",
    "                self.flush_curpar()\n",
    "                self.curpar.append( thing.text )\n",
    "                self.flush_curpar()\n",
    "\n",
    "\n",
    "            elif thing.name == 'a':\n",
    "                #print( 'A', thing )\n",
    "                self.links.append( urllib.parse.urljoin(page_url, thing.get('href') ) ) # resolve in context of page\n",
    "                self.curpar.append( thing.text )\n",
    "\n",
    "            elif thing.name == 'img':\n",
    "                pass # maybe add to self.images ?\n",
    "                #img_abs = urllib.parse.urljoin( page_url , thing.get('src'))  # TODO: look at all the attributes if we want to use it\n",
    "            elif thing.name == 'figure':\n",
    "                pass # maybe add to self.images ?\n",
    "                #img_abs = urllib.parse.urljoin( page_url , thing.get('src'))  # TODO: look at all the attributes if we want to use it\n",
    "\n",
    "            # not the cleanest; TODO: check that this works\n",
    "            elif thing.name == 'ol':\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'ul':\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'li':\n",
    "                self._handle(thing, page_url)\n",
    "\n",
    "\n",
    "            # this is dirty, because it's an extra cases, not recursion\n",
    "            elif thing.name == 'p':\n",
    "                #print('PPP')\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'div':\n",
    "                #print('DDD')\n",
    "                self._handle(thing, page_url)\n",
    "\n",
    "            # even nastier workaround\n",
    "            elif thing.name == 'table':\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'tbody':\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'thead': # maybe ignore?\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'tr':\n",
    "                self._handle(thing, page_url)\n",
    "            elif thing.name == 'td':\n",
    "                self._handle(thing, page_url)\n",
    "                self.flush_curpar() # TODO: check this makes sense.\n",
    "            elif thing.name == 'th':\n",
    "                self._handle(thing, page_url)\n",
    "                self.flush_curpar() # TODO: check this makes sense.\n",
    "\n",
    "            #elif type(thing) is bs4.NavigableString:\n",
    "            #    self.curpar.append( thing.text )\n",
    "            else:\n",
    "                raise ValueError( \"Don't know what to do with %r (on %r)\"%(thing, page_url))\n",
    "\n",
    "        self.flush_curpar() # TODO: check this always makes sense.\n",
    "\n",
    "\n",
    "def extract_from(page_url):\n",
    "    ''' Given the URL to an advice, fetches it, and extracts all interesting things\n",
    "    \n",
    "        CONSIDER: separate voetnoten\n",
    "    '''\n",
    "    ret = {}\n",
    "    page_data = rvs_fetched.get( page_url )\n",
    "\n",
    "    kenmerk = None\n",
    "    soup = bs4.BeautifulSoup( page_data, 'lxml' )\n",
    "    \n",
    "    title = soup.select('div.rol-paginatitel h1.grid-title')[0].text        \n",
    "\n",
    "    meta = {'trefwoorden':[]}\n",
    "    \n",
    "    ## Pick out metadata\n",
    "    last_dt = ''\n",
    "    metadata_blok_dl = soup.find('div',  attrs={'class':re.compile(r'\\brol-metadata-blok\\b')}).find('dl')\n",
    "    for ch in metadata_blok_dl.findAll(['dt','dd']):\n",
    "        if ch.name == 'dt':\n",
    "            last_dt = ch.text.strip()\n",
    "        elif ch.name == 'dd':\n",
    "            val = ch.text.strip()\n",
    "            try:\n",
    "                maanden = {\n",
    "                    'januari':1, 'februari':2, 'maart':3, 'april':4,  'mei':5,  'juni':6, 'juli':7,\n",
    "                    'augustus':8, 'september':9, 'october':10, 'oktober':10, 'november':11, 'december':12,\n",
    "                }\n",
    "                if 'Datum' in last_dt:\n",
    "                    day, month, year = val.split()\n",
    "                    if month.lower() in maanden:\n",
    "                        month = '%02d'%maanden[month.lower()]\n",
    "                    else:\n",
    "                        raise ValueError('not doing half a parse')\n",
    "                    val = '%04d-%s-%02d'%(int(year), month, int(day))\n",
    "\n",
    "                meta[last_dt] = val\n",
    "\n",
    "            except ValueError as e: # assume the date didn't manage to parse - we set the string as we got it\n",
    "                print(\"Didn't parse %r as date: %e\"%(val, e))\n",
    "                meta[last_dt] = val \n",
    "                \n",
    "        else:\n",
    "            raise ValueError(\"Don't understand dd child %r\"%ch.name)\n",
    "\n",
    "    trefwoorden_ul = soup.find('ul',  attrs={'class':re.compile(r'\\btrefwoorden\\b')})\n",
    "    for ch in trefwoorden_ul.findAll('li'):\n",
    "        meta['trefwoorden'].append( ch.text.strip() )\n",
    "\n",
    "    kenmerk = meta['Kenmerk']\n",
    "    if kenmerk is None:\n",
    "        raise ValueError( \"No kenmerk for %u\"%page_url )\n",
    "\n",
    "\n",
    "    ## Pick out \"Volledige tekst\" paragraphs\n",
    "    ep = ExtractParagraphs()\n",
    "\n",
    "    volledigetekst = soup.find(id='volledigetekst')\n",
    "    if volledigetekst is not None:\n",
    "        # TODO: fix this, it's not working\n",
    "\n",
    "        volledigetekst_div = volledigetekst.find( attrs={'class':re.compile(r'\\biprox-content\\b')} )\n",
    "        ep._handle( volledigetekst_div, page_url )\n",
    "\n",
    "        ret = {\n",
    "            'url':    page_url,\n",
    "            'kenmerk':kenmerk,\n",
    "            'title':  title,\n",
    "            'meta':   meta,\n",
    "            'body':   [],\n",
    "            'links':  ep.links,\n",
    "        }\n",
    "        for par in ep.pars:\n",
    "            ret['body'].append( par.replace('\\xa0',' ').strip() )\n",
    "        return ret\n",
    "    else:\n",
    "        raise ValueError('ERROR: no #volledigetekst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs_fetched = wetsuite.helpers.localdata.open_store('rvs_fetched.db', str, bytes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go through the webpage pages listing of all advices, and fetch each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010314464569091797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "fetching pages...",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d1e4cf733444b7aa468ed2c4d98d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fetching pages...:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxpage  = 0        # will soon be set to the real number, from the pages we fetch\n",
    "cur_page = 0        # zero-based counting in the pagination\n",
    "\n",
    "pbar = None \n",
    "\n",
    "count_fetched, count_cached = 0, 0\n",
    "\n",
    "while cur_page <= maxpage:\n",
    "    page_url = 'https://www.raadvanstate.nl/adviezen/?pager_page=%d&pager_rows=100'%cur_page\n",
    "    page_data = wetsuite.helpers.net.download(page_url)\n",
    "    soup = bs4.BeautifulSoup( page_data, 'lxml' )\n",
    "\n",
    "    # get the amount of pages, from the pagination links\n",
    "    pager_links = soup.select('a.pager_step')\n",
    "    for pager_link in pager_links:\n",
    "        try:\n",
    "            data_page = pager_link.get('data-page')\n",
    "            maxpage = max( maxpage, int(data_page))\n",
    "            if pbar==None and maxpage > 5:\n",
    "                pbar = wetsuite.helpers.notebook.progress_bar( max=maxpage, description='fetching pages...')\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print( \"WARNING: didn't understand %r as page number (%s)\"%(data_page, ve) )\n",
    "\n",
    "    #print( \"\\nPAGE %d of %d\"%( cur_page+1, maxpage+1 ) ) # numbering is zero-based,  print out one-based for humans\n",
    "\n",
    "    # fetch all links to specific case detail pages  -- URLs that look like https://www.raadvanstate.nl/adviezen/@133837/w02-22-00162-ii/\n",
    "    detail_page_urls = set( detail_page_a.get('href').split('#')[0]   for detail_page_a in soup.select('a[href*=\"/adviezen/@\"]') )    # these are already absolute  (otherwise we'd have to urljoin them)\n",
    "\n",
    "    #pprint.pprint(detail_page_urls)\n",
    "    for detail_page_url in detail_page_urls:\n",
    "        if '#' in detail_page_url:\n",
    "            detail_page_url = detail_page_url.split('#',1)[0]\n",
    "\n",
    "        # there seems to be nothing on the search result page that isn't on the detail pages, so we can just fetch now, and handle each individually later\n",
    "        # Such pages contain both samenvatting and volledigetekst, and the links to them are just #hash that presumably scripting pays attention to\n",
    "        bytedata, was_cached = wetsuite.helpers.localdata.cached_fetch( rvs_fetched, detail_page_url )\n",
    "        if not was_cached:\n",
    "            count_fetched += 1\n",
    "            #print(' FETCHED  - ', end='')\n",
    "            time.sleep( 1 ) # be somewhat nice to the server\n",
    "        else:\n",
    "            count_cached += 1\n",
    "            #print(' CACHED   - ', end='')\n",
    "            # TODO: if \"Vindplaats\" is just \"Website Raad van State\" (and date is relatively recent), try re-fetching.            \n",
    "\n",
    "\n",
    "        if 0: # debug - print a list of URLs with their titles\n",
    "            print('%-70s '%detail_page_url, end='')\n",
    "            print('%s '%detail_page_a.text)\n",
    "            print( extract_from( detail_page_url ) )\n",
    "            print()\n",
    "\n",
    "        pbar.description = 'fetching pages (%d cases fetched, %d cached)...'%(count_fetched, count_cached)\n",
    "\n",
    "    cur_page += 1\n",
    "    if pbar!=None:\n",
    "        pbar.value = cur_page\n",
    "    #break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go through fetched pages, massage into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01145482063293457,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "massaging...",
       "rate": null,
       "total": 11874,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a688044f954728a6fcfa1b1ba594c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "massaging...:   0%|          | 0/11874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = wetsuite.helpers.notebook.progress_bar( max=len(rvs_fetched), description='massaging...')\n",
    "\n",
    "for page_url in rvs_fetched.keys():\n",
    "    pbar.value += 1\n",
    "    item = extract_from( page_url )\n",
    "    #pprint.pprint( item )\n",
    "    #break\n",
    "    dataset[item.get('kenmerk')] = item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('W18.20.0171/IV',\n",
      " {'body': ['Bij Kabinetsmissive van 5 juni 2020, no.2020001125, heeft Uwe '\n",
      "           'Majesteit, op voordracht van de Minister van Economische Zaken en '\n",
      "           'Klimaat, bij de Afdeling advisering van de Raad van State ter '\n",
      "           'overweging aanhangig gemaakt het ontwerpbesluit tot wijziging van '\n",
      "           'het Besluit factuur, verbruiks- en indicatief kostenoverzicht '\n",
      "           'energie in verband met enkele aanpassingen betreffende de '\n",
      "           'implementatie van richtlijn 2012/27/EU betreffende '\n",
      "           'energie-efficiëntie, met nota van toelichting.',\n",
      "           'De Afdeling advisering van de Raad van State heeft geen '\n",
      "           'opmerkingen over het ontwerpbesluit en adviseert het besluit te '\n",
      "           'nemen.',\n",
      "           'Gelet op artikel 26, zesde lid jo vijfde lid, van de Wet op de '\n",
      "           'Raad van State, adviseert de Afdeling dit advies openbaar te '\n",
      "           'maken.',\n",
      "           'De vice-president van de Raad van State',\n",
      "           ''],\n",
      "  'kenmerk': 'W18.20.0171/IV',\n",
      "  'links': [],\n",
      "  'meta': {'Datum aanhangig': '2020-06-05',\n",
      "           'Datum advies': '2020-07-15',\n",
      "           'Datum publicatie': '2020-09-16',\n",
      "           'Datum vastgesteld': '2020-07-15',\n",
      "           'Kenmerk': 'W18.20.0171/IV',\n",
      "           'Vindplaats': 'Staatscourant 2020, nr. 49721',\n",
      "           'trefwoorden': ['Economische Zaken en Klimaat',\n",
      "                           'Algemene maatregel van bestuur']},\n",
      "  'title': 'Wijziging van het Besluit factuur, verbruiks- en indicatief '\n",
      "           'kostenoverzicht energie.',\n",
      "  'url': 'https://www.raadvanstate.nl/adviezen/@121305/w18-20-0171-iv/'})\n"
     ]
    }
   ],
   "source": [
    "# a random item, to check result of parse\n",
    "pprint.pprint( random.choice( list( dataset.items() )) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write dataset into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs_extracted = wetsuite.helpers.localdata.open_store('rvs_extracted.db', str, None, inst=wetsuite.helpers.localdata.MsgpackKV)\n",
    "rvs_extracted._put_meta('valtype','msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs_extracted._put_meta('descrition', '''\n",
    "These are a parsed form of Raad van State (state council) advice,\n",
    "specifically the set of documents under https://www.raadvanstate.nl/adviezen\n",
    "scraped into plain-text documents. \n",
    "\n",
    "Items look like:    \n",
    "'W01.19.0027/I': {'title': 'Voorstel van wet van het lid [...]',\n",
    "                'url': 'https://www.raadvanstate.nl/adviezen/@113252/w01-19-0027/'\n",
    "                'body': ['Bij brief van de voorzitter van de [...]',  # a list of paragraph-like fragments. \n",
    "                        ],\n",
    "                'links': ['http://www.rijksoverheid.nl/documenten/rapporten/2015/11/19/het-lokale-referendum-in-Nederland,).(156'],\n",
    "                'meta': {'Kenmerk': 'W01.19.0027/I',\n",
    "                            'trefwoorden': ['Algemene zaken', 'Initiatiefwet']\n",
    "                            'Datum aanhangig': '2019-01-30',\n",
    "                            'Datum advies': '2019-09-18',\n",
    "                            'Datum vastgesteld': '2019-09-18',\n",
    "                            'Datum publicatie': '2019-10-28',\n",
    "                            'Vindplaats': 'Kamerstukken II 2019/20, 35129, nr. 4', #  if at scraping time this was not settled, it will probably say \"Website Raad van State\" instead\n",
    "                        },\n",
    "                },\n",
    "\n",
    "This dataset generated on %s\n",
    "    '''%datetime.date.today().strftime('%Y-%m-%d'))\n",
    "\n",
    "for k, v in dataset.items():\n",
    "    rvs_extracted.put(k, v, commit=False)\n",
    "rvs_extracted.commit()\n",
    "#with open('raadvanstate_adviezen.json', 'w') as wf:\n",
    "#    wf.write( json.dumps(write_dataset) ) \n",
    "#wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('W15.17.0099/IV',\n",
       " {'url': 'https://www.raadvanstate.nl/adviezen/@64752/w15-17-0099-iv/',\n",
       "  'kenmerk': 'W15.17.0099/IV',\n",
       "  'title': 'Ontwerpbesluit tot wijziging van het Besluit diergeneeskundigen en het Besluit houders van dieren in verband met diverse wijzigingen op het gebied van dierenwelzijn, met nota van toelichting.',\n",
       "  'meta': {'trefwoorden': ['Economische Zaken en Klimaat',\n",
       "    'Algemene maatregel van bestuur'],\n",
       "   'Kenmerk': 'W15.17.0099/IV',\n",
       "   'Datum advies': '2017-06-02',\n",
       "   'Vindplaats': 'Staatcourant 2018, nr. 28779'},\n",
       "  'body': ['Ontwerpbesluit tot wijziging van het Besluit diergeneeskundigen en het Besluit houders van dieren in verband met diverse wijzigingen op het gebied van dierenwelzijn, met nota van toelichting.',\n",
       "   'Bij Kabinetsmissive van 3 april 2017, no.2017000594, heeft Uwe Majesteit, op voordracht van de Staatssecretaris van Economische Zaken, bij de Afdeling advisering van de Raad van State ter overweging aanhangig gemaakt het ontwerpbesluit tot wijziging van het Besluit diergeneeskundigen en het Besluit houders van dieren in verband met diverse wijzigingen op het gebied van dierenwelzijn, met nota van toelichting.',\n",
       "   'Het ontwerpbesluit voert een aantal wijzigingen door op het gebied van dierenwelzijn. Zo komt er onder meer een verbod op het aanbrengen van een neusring bij mannelijke fokvarkens en een verbod op het vriesbranden van runderen. Ook wordt de elektronische halsband slechts onder voorwaarden toegestaan en wordt de scheidingsleeftijd van apen en konijnen bepaald.',\n",
       "   'De Afdeling advisering van de Raad van State adviseert het ontwerpbesluit vast te stellen, maar maakt twee opmerkingen met betrekking tot elektronische apparatuur.',\n",
       "   '1.',\n",
       "   'Elektronische apparatuur',\n",
       "   'Het ontwerpbesluit voegt aan de lijst met verboden gedragingen ten aanzien van dieren onder meer toe het gebruik van apparatuur waarmee een dier door middel van stroomstoten, elektromagnetische signalen of straling pijn kan worden toegebracht. Apparatuur waarvan het gebruik is gericht op het bewerkstelligen van een gerechtvaardigde gedragsverandering bij het dier ter voorkoming van gevaar voor mens of dier of van aantasting van het welzijn van het dier en de houder daarvoor over voldoende deskundigheid beschikt, is wel toegestaan.  (zie noot 1)  Elektronische apparatuur is bijvoorbeeld een koetrainer  (zie noot 2) , een elektronische halsband of anti blafband voor honden.',\n",
       "   'Om het risico op welzijnsaantasting te verminderen, wordt bepaald dat het gebruik slechts is toegestaan indien de houder daarvoor over voldoende deskundigheid beschikt. De borging van de deskundigheid kan geschieden door bijvoorbeeld het stellen van opleidingseisen dan wel de eis dat de band alleen wordt gebruikt onder toezicht en op advies van een persoon die een dergelijke cursus heeft gehad.  (zie noot 3)  De regels omtrent de deskundigheid, alsmede de wijze waarop de aanwezigheid daarvan kan worden aangetoond, zullen op basis van artikel 2.1, vierde lid, van de Wet dieren, bij ministeriële regeling regels worden gesteld.  (zie noot 4)',\n",
       "   'In de diverse reacties uit de consultatie blijkt dat met name verschillend naar elektronische halsbanden wordt gekeken. Waar de ene organisatie  (zie noot 5)  pleit voor een volledige verbod op elektronische halsbanden, pleiten andere organisaties  (zie noot 6)  voor regulering.',\n",
       "   'De Afdeling maakt met betrekking tot elektronische apparatuur twee opmerkingen.',\n",
       "   'Het verbod om gebruik te maken van apparatuur zonder over voldoende deskundigheid te beschikken ziet op apparatuur die zeer verschillend van aard is. Naar het oordeel van de Afdeling is het verbod in veel gevallen echter niet of nauwelijks handhaafbaar. Dit geldt in ieder geval voor de elektronische halsband en de anti blafband, omdat de bezitters van honden in beginsel niet georganiseerd zijn. De elektronische halsbanden en anti blafbanden zullen verkrijgbaar blijven, omdat de wetgeving hieraan niet in de weg staat, terwijl slechts een relatief beperkte groep van (professionele) gebruikers zich bewust zal zijn van het verbod en zal weten dat gebruik alleen is toegestaan indien aan de gestelde eisen is voldaan.',\n",
       "   'Ten tweede maakt de toelichting niet duidelijk of de ministeriële regeling ook technische eisen zal stellen ten aanzien van de apparatuur. Nu de apparatuur gericht moet zijn op het bewerkstelligen van een gerechtvaardigde gedragsverandering bij het dier ter voorkoming van gevaar voor mens of dier of van aantasting van het welzijn van het dier, ligt het voor de hand bijvoorbeeld een maximaal te hanteren voltage voor elektronische halsbanden en/of anti blafbanden in de ministeriële regeling op te nemen.  (zie noot 7)',\n",
       "   'De Afdeling adviseert om redenen van handhaafbaarheid af te zien van het deskundigheidsvereiste, in elk geval bij gebruik van apparatuur bij hobby- en gezelschapsdieren. Wel geeft de Afdeling in overweging aan deze apparatuur technische eisen te stellen.',\n",
       "   '2.',\n",
       "   'De Afdeling verwijst naar de bij dit advies behorende redactionele bijlage.',\n",
       "   'De Afdeling advisering van de Raad van State geeft U in overweging in dezen een besluit te nemen, nadat met het vorenstaande rekening zal zijn gehouden.',\n",
       "   'De vice-president van de Raad van State',\n",
       "   '',\n",
       "   'Redactionele bijlage bij het advies van de Afdeling advisering van de Raad van State betreffende no.W15.17.0099/IV',\n",
       "   '- In de toelichting (paragraaf 5 Notificatie) ‘richtlijn nr. 98/34/EG’ vervangen door: richtlijn 2015/1535/EU.',\n",
       "   '',\n",
       "   '',\n",
       "   'Nader rapport (reactie op het advies) van 25 april 2018',\n",
       "   '',\n",
       "   '',\n",
       "   'Het ontwerp geeft de Afdeling aanleiding tot het maken van twee opmerkingen. Beide opmerkingen hebben betrekking op het onder voorwaarden toestaan van het gebruik van elektronische apparatuur. Het deskundigheidsvereiste, zoals dat is opgenomen in artikel II, onderdeel A, van het ontwerp, is onmisbaar om aantasting van het welzijn van het dier als gevolg van het ondeskundig gebruik van de apparatuur tegen te gaan. Van het verbod om gebruik te maken van apparatuur zonder over voldoende deskundigheid te beschikken, gaat een belangrijke werking uit. Het verbod is goed handhaafbaar aangezien onder het gebruik van een dergelijke band ook het enkele omhebben door het dier, moet worden verstaan. De nota van toelichting is op dit punt aangevuld.',\n",
       "   'Op basis van artikel 2.1, vierde lid, van de Wet dieren zullen bij ministeriële regeling regels worden gesteld omtrent de vereiste deskundigheid bij de gebruiker van elektronische apparatuur waarvan het gebruik is gericht op het bewerkstellingen van een gerechtvaardigde gedragsverandering bij het dier. In deze regeling zullen ook technische eisen worden gesteld ten aanzien van die apparatuur.',\n",
       "   'De redactionele kanttekening van de Afdeling is verwerkt.',\n",
       "   'Ik moge U hierbij het ontwerpbesluit en de gewijzigde nota van toelichting doen toekomen en U verzoeken overeenkomstig dit ontwerp te besluiten.',\n",
       "   'De Minister van Landbouw, Natuur en Voedselkwaliteit',\n",
       "   '',\n",
       "   '(1) Artikel II, onderdeel A, onder h, voorstel.',\n",
       "   '(2) Een zogenoemde ‘koetrainer’ kan gebruikt worden om de ligplek van de aangebonden koe schoon te houden. Koetrainers zijn elektrische stroomdraden die boven de rug van de koe worden gehangen. Bij het mesten of urineren krijgen koeien een elektrische schok, zodat ze een stap naar achter doen en het ligbed schoon blijft.',\n",
       "   '(3) Toelichting, paragraaf 3.',\n",
       "   '(4) Toelichting, Artikel II (wijzigingen Besluit houders van dieren), onderdeel A.',\n",
       "   '(5) Reactie Dierenbescherming, 27 augustus 2014.',\n",
       "   '(6) Reactie Koninklijke Nederlandse Politiehond Vereniging, 30 augustus 2014 of Koninklijke Hondenbescherming, 23 juli 2014 (regulering indien geen verbod).',\n",
       "   '(7) Vergelijk ook: Reactie Dierenbescherming, 27 augustus 2014, onder verbod elektronische halsband honden.',\n",
       "   '',\n",
       "   'Gehele tekst ontwerpregeling met toelichting (pdf, 248 kB)',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   ''],\n",
       "  'links': ['https://www.raadvanstate.nl/publish/pages/108273/w-15-17-0099.pdf']})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that worked\n",
    "print( len(rvs_extracted) )\n",
    "random.choice( list(rvs_extracted.items()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
