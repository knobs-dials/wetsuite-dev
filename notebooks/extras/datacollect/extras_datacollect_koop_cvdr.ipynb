{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "Show how we fetch data from the CVDR repository to be used to create our corresponding datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, pprint\n",
    "import tqdm\n",
    "import wetsuite.helpers.etree\n",
    "import wetsuite.helpers.localdata\n",
    "import wetsuite.datacollect.koop_repositories \n",
    "import wetsuite.helpers.koop_parse\n",
    "import wetsuite.helpers.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fetch script has previously saved downloads into:\n",
    "cvdr_fetched         = wetsuite.helpers.localdata.LocalKV( 'cvdr_fetched.db', str, bytes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010372638702392578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "fetching",
       "rate": null,
       "total": 8179,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e45177ecfcb44969b1433bcbb0eb94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fetching:   0%|          | 0/8179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010545492172241211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "fetching",
       "rate": null,
       "total": 14254,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4005a1a29c415fa2c2168da0263b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fetching:   0%|          | 0/14254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload( wetsuite.helpers.notebook )\n",
    "\n",
    "sru_cvdr = wetsuite.datacollect.koop_repositories.CVDR()\n",
    "\n",
    "queries = [ \n",
    "    # the time period is balanced with the up_to later.  No real reason to the choices.\n",
    "    #'dcterms.modified>=2023-01-01',\n",
    "\n",
    "    #'dcterms.modified>=2023-06-01 and dcterms.modified<=2023-12-31',\n",
    "    #'dcterms.modified>=2023-01-01 and dcterms.modified<=2023-06-01',\n",
    "    #'dcterms.modified>=2022-06-01 and dcterms.modified<=2022-12-31',\n",
    "    #'dcterms.modified>=2022-01-01 and dcterms.modified<=2022-06-01',\n",
    "    #'dcterms.modified>=2021-06-01 and dcterms.modified<=2021-12-31',\n",
    "    #'dcterms.modified>=2021-01-01 and dcterms.modified<=2021-06-01',\n",
    "    #'dcterms.modified>=2020-06-01 and dcterms.modified<=2020-12-31',\n",
    "    #'dcterms.modified>=2020-01-01 and dcterms.modified<=2020-06-01',\n",
    "    'dcterms.modified>=2019-06-01 and dcterms.modified<=2019-12-31',\n",
    "    'dcterms.modified>=2019-01-01 and dcterms.modified<=2019-06-01',\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    sru_cvdr.search_retrieve( query ) # purely for the number of records, itself only for the progress bar\n",
    "    numrecs = sru_cvdr.num_records()\n",
    "    pbar = wetsuite.helpers.notebook.progress_bar( max=numrecs, description='fetching')\n",
    "\n",
    "    count_cached, count_fetched = 0,0\n",
    "    def cvdr_callback(record):\n",
    "        global count_cached, count_fetched\n",
    "        merged = {}\n",
    "\n",
    "        #recordSchema   = record.find('recordSchema')      # e.g. <recordSchema>http://standaarden.overheid.nl/sru/</recordSchema>\n",
    "        #recordPacking  = record.find('recordPacking')     # probably <recordPacking>xml</recordPacking>\n",
    "        recordData     = record.find('recordData')        # the actual record \n",
    "        recordPosition = record.find('recordPosition')    # e.g. <recordPosition>12</recordPosition>\n",
    "\n",
    "        gzd = recordData[0]\n",
    "        originalData = gzd.find('originalData')\n",
    "        merged.update( wetsuite.helpers.etree.kvelements_to_dict( originalData.find('meta/owmskern')   ) )\n",
    "        merged.update( wetsuite.helpers.etree.kvelements_to_dict( originalData.find('meta/owmsmantel') ) )\n",
    "        merged.update( wetsuite.helpers.etree.kvelements_to_dict( originalData.find('meta/cvdripm')     )  )\n",
    "        merged.update( wetsuite.helpers.etree.kvelements_to_dict( gzd.find('enrichedData') ) )\n",
    "        #pprint.pprint( merged )\n",
    "\n",
    "        try:\n",
    "            _, came_from_cache = wetsuite.helpers.localdata.cached_fetch( cvdr_fetched, merged['publicatieurl_xml'] ) # we currently care only about the XML it links to\n",
    "            if not came_from_cache:\n",
    "                count_fetched += 1\n",
    "                #print( \"FETCHED : %r\"%(merged['publicatieurl_xml']))\n",
    "                #time.sleep( 1 ) # be somewhat nice to server\n",
    "            else:\n",
    "                count_cached += 1\n",
    "                #print( \"CACHED : %r\"%(merged['publicatieurl_xml']))\n",
    "        except ValueError as ve:\n",
    "            print( \"ERROR downloading: %s  for %r\"%(ve, merged['publicatieurl_xml']))\n",
    "\n",
    "        pbar.value += 1\n",
    "        if pbar.value % 25 == 0:\n",
    "            pbar.description = '%d cached, %d fetched'%(count_cached, count_fetched)\n",
    "        \n",
    "    _ = sru_cvdr.search_retrieve_many( query, at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "    #_ = sru_cvdr.search_retrieve_many( query, at_a_time=1000, up_to=50000, callback=cvdr_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "\n",
    "#sru_cvdr.search_retrieve_many(\"creator any Delft\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"creator any Amsterdam\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"creator any Utrecht\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "\n",
    "#sru_cvdr.search_retrieve_many(\"title any Damocles or title any damoclesbeleid\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"title any Opiumwet and title any 13b\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"title any Opiumwet and title any 13\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"dcterms.source any BWBR0001941\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"dcterms.source any 13b\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"dcterms.source any opiumwet\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"isFormatOf='CVDR640125'\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#  https://repository.officiele-overheidspublicaties.nl/CVDR/CVDR640125/1/xml/CVDR640125_1.xml\n",
    "\n",
    "\n",
    "#sru_cvdr.search_retrieve_many('dcterms.modified>=2022-06-01', at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many('dcterms.modified>=2022-01-01 and dcterms.modified<=2022-06-01', at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many('dcterms.modified>=2021-01-01 and dcterms.modified<=2021-12-31', up_to=50000, callback=cvdr_callback) \n",
    "#sru_cvdr.search_retrieve_many('dcterms.modified>=2013-01-01 and dcterms.modified<=2013-12-31', up_to=50000, callback=cvdr_callback) \n",
    "#sru_cvdr.search_retrieve_many('dcterms.modified<=2012-12-31', up_to=50000, callback=cvdr_callback) \n",
    "\n",
    "# doesn't seem to let you search for \"all versions of\"\n",
    "#sru_cvdr.search_retrieve_many(\"dcterms.identifier=CVDR272112_2\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "#sru_cvdr.search_retrieve_many(\"dcterms.identifier=CVDR272112\", at_a_time=1000, up_to=50000, callback=cvdr_callback)\n",
    "\n",
    "# ERROR case\n",
    "#sru_cvdr.search_retrieve_many(\"dcterms.identifier=CVDR7915_1\", at_a_time=1000, up_to=50000, callback=cvdr_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "\n",
    "We'll spare you the full contents of that store,\n",
    "because it contains most versions of most things, is even more overcomplete than that, and probably not something you want to fetch yourself.\n",
    "\n",
    "Mostly for our own reference, it contains keys that are URLs like:\n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/html/100078_1.html\n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml\n",
    "and values that are said files as bytestrings.\n",
    "\n",
    "Right now we care about data, so just the XML, so we ignore everything else.\n",
    "\n",
    "Also, it seems that KOOP search results expose some variation in the capitalisation, led to duplicate URLs in the above, e.g. \n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml\n",
    "- https://repository.officiele-overheidspublicaties.nl/cvdr/100078/1/xml/100078_1.xml\n",
    "\n",
    "...so we also ensure we pick just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432294 182492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dedupdata   = collections.defaultdict(list)  # lowercased version of URL -> actual URLs\n",
    "for url in cvdr_fetched:\n",
    "    if not url.endswith('.xml'):\n",
    "        continue\n",
    "    dedupdata[ url.lower() ].append( url )\n",
    "\n",
    "unique_xml_urls = []\n",
    "for lurl in list(dedupdata):\n",
    "     url_list = sorted( dedupdata[lurl] ) #some consistency in which one we pick\n",
    "     unique_xml_urls.append( url_list[0] )\n",
    "     #print( url_list )\n",
    "\n",
    "print( len(cvdr_fetched), len( unique_xml_urls ) )\n",
    "\n",
    "## This was some double checking they have identical content   (and count how many of these duplicates are there)\n",
    "# def nxml(bytedata): # reindent as a form of normalization\n",
    "#     tree = wetsuite.helpers.etree.fromstring(bytedata)\n",
    "#     tree = wetsuite.helpers.etree.indent( tree )\n",
    "#     return wetsuite.helpers.etree.tostring( tree, encoding='UTF-8' ) \n",
    "# counts = collections.defaultdict(int)        # how many -> how often\n",
    "# for lurl in list(dedupdata):\n",
    "#     url_list = dedupdata[lurl]\n",
    "#     xml_list = list( cvdr_fetched.get(url)   for url in url_list )\n",
    "#     lxl = len(xml_list)\n",
    "#     counts[lxl]+=1\n",
    "#     if lxl > 1:\n",
    "#         print( url_list )\n",
    "#         norm_xml_list = list( nxml( cvdr_fetched.get(url) )    for url in url_list )\n",
    "#         for i in range( 1, len(norm_xml_list) ):\n",
    "#             is_same = norm_xml_list[0] == norm_xml_list[i]\n",
    "#             #print(\"cmp(0,%d)==%s\"%(i, is_same))\n",
    "#             if not is_same:\n",
    "#                 print('%s not the same as %s'%(url_list[0], url_list[i]))\n",
    "#                 print(difflib.context_diff(norm_xml_list[0].splitlines(), norm_xml_list[i].splitlines()))\n",
    "#pprint.pprint(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182492 167416 167416\n"
     ]
    }
   ],
   "source": [
    "cvdr_groups = collections.defaultdict(list)  # CVDR-workid -> [ (expression_id, xml_url), ... ]\n",
    "\n",
    "# Now group expressions by their work ID \n",
    "groups = collections.defaultdict(list)   # work_id -> [ (version_in_expression_id, expression_id, url), ... ]\n",
    "\n",
    "for url in unique_xml_urls:\n",
    "    ids = url.rsplit('/',1)[1].rsplit('.',1)[0]\n",
    "    work_id, expression_id = wetsuite.helpers.koop_parse.cvdr_parse_identifier(ids)\n",
    "    version_int = int( expression_id.split('_',1)[1], 10)  # for sorting\n",
    "    #print (work_id, expression_id, url)\n",
    "    groups[work_id].append( (version_int, expression_id, url) )\n",
    "\n",
    "lasts_only = []   # was dict  url -> data\n",
    "for work_id in groups:\n",
    "    expression_and_urls = sorted( groups[work_id] )   # (sorting defaults to first column)\n",
    "    version_int, expression_id, url = expression_and_urls[-1] #right now we just pick the last revision\n",
    "    #TODO: check the actual validity date.   Right now it will pick a few of the 'planned for the near future' ones\n",
    "    lasts_only.append( url )\n",
    "\n",
    "print( len( unique_xml_urls ), len(groups), len(lasts_only) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a store that intends to contain just the most recent expression XML for each work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167416/167416 [00:51<00:00, 3249.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# takes minute or to just to write that much data  (order of a few GB)\n",
    "cvdr_latestonly_xml = wetsuite.helpers.localdata.LocalKV( 'cvdr_latestonly_xml.db', str, bytes )\n",
    "for url in tqdm.tqdm( lasts_only ):\n",
    "    cvdr_latestonly_xml.put( url, cvdr_fetched.get( url ), commit=False )\n",
    "cvdr_latestonly_xml.commit() # reducing that many commits is factor dozens speed difference (on SSD)\n",
    "cvdr_latestonly_xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6405173248"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvdr_latestonly_xml.bytesize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and stores that contain the plain text, and the metadata, for the same latest expressions. \n",
    "\n",
    "These three stores should have exactly the same keys (unless maybe we forget to clean the lastest leftoves betwen rerunning this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169421/169421 [10:06<00:00, 279.53it/s]\n"
     ]
    }
   ],
   "source": [
    "cvdr_latestonly_text = wetsuite.helpers.localdata.LocalKV( 'cvdr_latestonly_text.db', str, str )\n",
    "cvdr_latestonly_text._put_meta('description','') # metadata for each CVDR item. Mostly just the output of wetsuite.helpers.koop_parse.cvdr_text\n",
    "\n",
    "cvdr_latestonly_meta = wetsuite.helpers.localdata.MsgpackKV( 'cvdr_latestonly_meta.db', str, None)\n",
    "cvdr_latestonly_meta._put_meta('valtype','msgpack')\n",
    "cvdr_latestonly_meta._put_meta('description','') # metadata for each CVDR item. Mostly just the output of wetsuite.helpers.koop_parse.cvdr_meta\n",
    "\n",
    "cvdr_latestonly_xml = wetsuite.helpers.localdata.LocalKV( 'cvdr_latestonly_xml.db', str, bytes, read_only=True )\n",
    "\n",
    "for url, xml_bytes in tqdm.tqdm( cvdr_latestonly_xml.items() ):\n",
    "        tree = wetsuite.helpers.etree.fromstring( xml_bytes )\n",
    "        \n",
    "        meta = wetsuite.helpers.koop_parse.cvdr_meta(tree, flatten=True)\n",
    "        #pprint.pprint(meta)\n",
    "        cvdr_latestonly_meta.put(url, meta, commit=False)\n",
    "\n",
    "        text = wetsuite.helpers.koop_parse.cvdr_text(tree)\n",
    "        #print(repr(text))\n",
    "        cvdr_latestonly_text.put(url, text, commit=False)\n",
    "        \n",
    "        #break\n",
    "cvdr_latestonly_meta.commit()\n",
    "cvdr_latestonly_text.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
