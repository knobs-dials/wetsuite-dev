#!/usr/bin/python3
'''
    Takes a directory of downloadable files, 
    generates the metadata used for the index.
'''
import os
import sys
import glob
import pprint
import tempfile
import json
import lzma  # >= py3.3

#import wetsuite.helpers.util
import wetsuite.helpers.localdata
import wetsuite.helpers.format


# a local cache that avoids a bunch of repeated reading on unchanged uploads
dataset_meta = wetsuite.helpers.localdata.MsgpackKV('dataset_meta.db')

dataset_index = {} # this is headed for a json file to be served

#dataset_meta.truncate()  # TODO: remove, this was a debug thing



if __name__ == '__main__':

    # hardcoded for now
    

    args = sys.argv[1:]
    if len(args) != 1:
        print("We want one argument, a directory to look for files in")
        sys.exit(-1)

    in_dir           = args[0] 

    dataset_index_fn = os.path.join( in_dir, 'index.json' )


    fns = glob.glob( os.path.join( os.path.abspath(in_dir), '*') ) # *xz
    for fn in fns:
        ffn = os.path.join( in_dir, fn )
        basename = os.path.basename(fn)
        if basename == 'index.json':
            continue
        #print(' ====== %r ====== '%basename)

        stob = os.stat(ffn)

        if stob.st_size > 500000000:
            print("LARGE, skip during this debug")
            continue

        key = '__/__'.join( [ ffn, str( stob.st_size ), str( int(stob.st_mtime) ) ] )


        if key in dataset_meta:
            print( "NOCALC, we know about %r"%ffn)
            stored_dict = dataset_meta.get( key )

        else:  # key not in dataset_meta:
            stored_dict = {
                'basename':             basename,
                'compressed_size':      stob.st_size,
                'compressed_size_human':'%sB'%wetsuite.helpers.format.kmgtp(stob.st_size),
                'mtime':                int(stob.st_mtime),
            }

            filetype = None
            if ffn.endswith('.xz'):
                filetype = 'xz'

            else:
                with open(ffn, 'rb') as f:
                    firstbytes = f.read(20)
                if firstbytes[:7] == b'\xfd7zXZ\x00\x00':
                    filetype='xz'
                elif firstbytes[:15] == b'SQLite format 3': # shouldn't happen here, but we will probably end up sharing this logic elsewhere
                    filetype='sqlite3'
                elif firstbytes.lstrip().startswith(b'{'):
                    filetype='json'

            print( "  uncompressing %s to get its real size, please wait"%ffn )

            if filetype == 'xz':           # TODO: bz2, gz
                stored_dict['type'] = 'xz-sqlite3'
                print( "DO XZ %r"%ffn)

                print("\nDETERMINE uncompressed size of %r"%ffn)
                uncompressed_data_size_bytes = 0
                with tempfile.NamedTemporaryFile() as temp_file:
                    # the only reason we do this is description, maybe think of a more efficient way that doesn't rely on lots of storage being there
                    print( "    into temporary file %r"%temp_file.name ) 
                    with lzma.open( ffn ) as compressed_file_object:
                        while True:
                            data = compressed_file_object.read( 2*1048576 )
                            if len(data) == 0:
                                break
                            temp_file.write(data)
                            uncompressed_data_size_bytes += len( data )
                            print( "\r    decompressing... %3sB    "%(wetsuite.helpers.format.kmgtp( uncompressed_data_size_bytes, kilo=1024 ), ),
                                   end='', file=sys.stderr )
                    print()
                    stored_dict['uncompressed_size'] = uncompressed_data_size_bytes
                    #stored_dict['uncompressed_size_human'] = '%sB'%wetsuite.helpers.format.kmgtp(uncompressed_data_size_bytes, kilo=1024)

                    with wetsuite.helpers.localdata.LocalKV( temp_file.name, None,None, read_only=True ) as tstore:
                        stored_dict['description'] = tstore._get_meta('description', missing_as_none=True)


            elif filetype == 'sqlite3': # TODO: remove need (we want downloads to be compressed always)
                stored_dict['type'] = 'sqlite3'
                print( "DO SQLITE3 %r"%ffn)

                stored_dict['uncompressed_size'] = stored_dict['compressed_size']
                #stored_dict['uncompressed_size_human'] = '%sB'%wetsuite.helpers.format.kmgtp( stored_dict['uncompressed_size'], kilo=1024 )

                with wetsuite.helpers.localdata.LocalKV( ffn, None,None, read_only=True ) as tstore:
                    stored_dict['description'] = tstore._get_meta('description', missing_as_none=True)


            elif filetype == 'json': # CONSIDER: remove need (we want downloads to be compressed always)
                stored_dict['type'] = 'json'
                print( "DO JSON %r"%ffn)

                stored_dict['uncompressed_size'] = stored_dict['compressed_size']
                #stored_dict['uncompressed_size_human'] = '%sB'%wetsuite.helpers.format.kmgtp( stored_dict['uncompressed_size'], kilo=1024 )


            else:
                print( "TODO: handle %s %r"%(filetype, ffn) )
                continue


            dataset_meta.put(key, stored_dict)


        ## Either way, describe the thing in the index
        dataset_name = basename.split('.',1)[0]

        dataset_item = {}
        dataset_item['name']                = dataset_name
        dataset_item['url']                 = 'https://wetsuite.knobs-dials.com/datasets/%s'%basename
        dataset_item['version']             = stored_dict.get('version', '(preliminary)')
        dataset_item['type']                = stored_dict.get('type')
        dataset_item['description_short']   = stored_dict.get('description_short')
        dataset_item['description']         = stored_dict.get('description')
        dataset_item['download_size']       = stored_dict.get('compressed_size')
        dataset_item['real_size']           = stored_dict.get('uncompressed_size')
        dataset_item['download_size_human'] = '%sB'%wetsuite.helpers.format.kmgtp( stored_dict.get('compressed_size'), kilo=1024   )
        dataset_item['real_size_human']     = '%sB'%wetsuite.helpers.format.kmgtp( stored_dict.get('uncompressed_size'), kilo=1024 )

        dataset_index[dataset_name] = dataset_item



print( "Writing %r"%dataset_index_fn )
with open( dataset_index_fn, 'w', encoding='utf8') as wf:
    wf.write( json.dumps( dataset_index ) )

